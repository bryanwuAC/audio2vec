{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import ast\n",
    "import pickle\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperparameters as hps\n",
    "from embedding import embedding as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    path = os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "                tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        tracks['set', 'subset'] = tracks['set', 'subset'].astype(pd.api.types.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "        \n",
    "        \n",
    "\n",
    "#         COLUMNS = [('track', 'license'), ('artist', 'bio'),\n",
    "#                    ('album', 'type'), ('album', 'information')]\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype(pd.api.types.CategoricalDtype())\n",
    "\n",
    "        return tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file_name, file_data):\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(file_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name):\n",
    "    with open(file_name, \"rb\") as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction_func(x, sr):\n",
    "    stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "    mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_extraction_func(x, sr):\n",
    "    cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12, n_bins=7*12, tuning=None))\n",
    "    f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and features.\n",
    "BAD_TRACK_ID = [98565, 98567, 98569, 99134, 108925, 133297]\n",
    "\n",
    "tracks = load('../fma_metadata/tracks.csv')\n",
    "tracks = tracks.drop(labels = BAD_TRACK_ID)\n",
    "\n",
    "genres = load('../fma_metadata/genres.csv')\n",
    "features = load('../fma_metadata/features.csv')\n",
    "features = features.drop(labels = BAD_TRACK_ID)\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"fma_small\"\n",
    "extracted_features = []\n",
    "small = tracks['set', 'subset'] <= 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(query, documents, document_ids, dist_func='cos', num_results=10):\n",
    "    distances = np.zeros(documents.shape[0])\n",
    "    for i in range(documents.shape[0]):\n",
    "        if dist_func == 'cos':\n",
    "            distances[i] = distance.cosine(query, documents[i])\n",
    "        elif dist_func == 'norm':\n",
    "            distances[i] = np.linalg.norm(documents[i] - query)\n",
    "    ranking_result_index = np.argsort(distances)\n",
    "    return document_ids[ranking_result_index[:num_results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_noise_to_wave(x, noise_level):\n",
    "    x += noise_level * np.random.rand(len(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noised_audio_features(filename, feature_extraction_func, noise_level):\n",
    "    x, sr = librosa.load(\"../\"+filename, sr=None, mono=True)\n",
    "    x = x[:(10*sr)]\n",
    "    # adding distortion to loaded wave\n",
    "    x = add_random_noise_to_wave(x, noise_level)\n",
    "    extracted_features = feature_extraction_func(x, sr)\n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(all_track_ids, feature_extraction_func, noise_level=0.01, num_data=100):\n",
    "    test_track_ids = np.random.choice(all_track_ids, num_data, replace=False)\n",
    "    test_data = []\n",
    "    for track_id in test_track_ids:\n",
    "        filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "        test_feature = get_noised_audio_features(filename, feature_extraction_func, noise_level)\n",
    "        print(\"Creating test data:\", track_id)\n",
    "        test_data.append(test_feature)\n",
    "    return test_track_ids, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(all_track_ids, all_embedding, test_track_ids, test_embedding, dist_func='cos'):\n",
    "    correct_ranking = 0\n",
    "    ranking_result_list = []\n",
    "    for i, test_track_id in enumerate(test_track_ids):\n",
    "        query_track_id = test_track_ids[i]\n",
    "        query = test_embedding[i]\n",
    "        \n",
    "        ranking_result = ranking(query, all_embedding, all_track_ids, dist_func)\n",
    "        ranking_result_list.append(ranking_result)\n",
    "        \n",
    "        if ranking_result[0] == query_track_id:\n",
    "            correct_ranking += 1\n",
    "    accuracy = correct_ranking / len(test_track_ids)\n",
    "    print ('Accuracy is {}.'.format(accuracy))\n",
    "    return test_track_ids, ranking_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = \"mfcc\"\n",
    "model_file_name = \"{}/sec2sec_{}_{}.pkl\".format(hps.model_dir, feature_name, 5900)\n",
    "all_embedding_file_name = \"{}_embedding_vector.pkl\".format(feature_name)\n",
    "test_data_file_name = \"test_data_{}.pkl\".format(feature_name)\n",
    "\n",
    "# Load all embedding vectors\n",
    "all_embedding = load_pickle(all_embedding_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data: 69198\n",
      "Creating test data: 104062\n",
      "Creating test data: 98582\n",
      "Creating test data: 32686\n",
      "Creating test data: 29602\n",
      "Creating test data: 110634\n",
      "Creating test data: 62529\n",
      "Creating test data: 27177\n",
      "Creating test data: 54665\n",
      "Creating test data: 111392\n",
      "Creating test data: 12051\n",
      "Creating test data: 113699\n",
      "Creating test data: 128845\n",
      "Creating test data: 11775\n",
      "Creating test data: 78516\n",
      "Creating test data: 90616\n",
      "Creating test data: 55122\n",
      "Creating test data: 59449\n",
      "Creating test data: 21401\n",
      "Creating test data: 111372\n",
      "Creating test data: 40984\n",
      "Creating test data: 124394\n",
      "Creating test data: 107125\n",
      "Creating test data: 24427\n",
      "Creating test data: 86263\n",
      "Creating test data: 55811\n",
      "Creating test data: 42659\n",
      "Creating test data: 81037\n",
      "Creating test data: 68851\n",
      "Creating test data: 98251\n",
      "Creating test data: 148537\n",
      "Creating test data: 69195\n",
      "Creating test data: 60038\n",
      "Creating test data: 80680\n",
      "Creating test data: 86634\n",
      "Creating test data: 111150\n",
      "Creating test data: 130933\n",
      "Creating test data: 121366\n",
      "Creating test data: 115849\n",
      "Creating test data: 87157\n",
      "Creating test data: 116547\n",
      "Creating test data: 145475\n",
      "Creating test data: 73560\n",
      "Creating test data: 114293\n",
      "Creating test data: 82917\n",
      "Creating test data: 20361\n",
      "Creating test data: 80754\n",
      "Creating test data: 132118\n",
      "Creating test data: 38321\n",
      "Creating test data: 54576\n",
      "Creating test data: 110648\n",
      "Creating test data: 133972\n",
      "Creating test data: 143039\n",
      "Creating test data: 112315\n",
      "Creating test data: 47661\n",
      "Creating test data: 80766\n",
      "Creating test data: 132679\n",
      "Creating test data: 122500\n",
      "Creating test data: 117945\n",
      "Creating test data: 72738\n",
      "Creating test data: 10382\n",
      "Creating test data: 138017\n",
      "Creating test data: 75395\n",
      "Creating test data: 58053\n",
      "Creating test data: 20704\n",
      "Creating test data: 62005\n",
      "Creating test data: 136708\n",
      "Creating test data: 98656\n",
      "Creating test data: 52638\n",
      "Creating test data: 39378\n",
      "Creating test data: 55293\n",
      "Creating test data: 24983\n",
      "Creating test data: 114533\n",
      "Creating test data: 87121\n",
      "Creating test data: 87188\n",
      "Creating test data: 59686\n",
      "Creating test data: 111390\n",
      "Creating test data: 130940\n",
      "Creating test data: 39667\n",
      "Creating test data: 125154\n",
      "Creating test data: 55783\n",
      "Creating test data: 144471\n",
      "Creating test data: 107567\n",
      "Creating test data: 73172\n",
      "Creating test data: 109355\n",
      "Creating test data: 148\n",
      "Creating test data: 110084\n",
      "Creating test data: 58341\n",
      "Creating test data: 88870\n",
      "Creating test data: 51005\n",
      "Creating test data: 115850\n",
      "Creating test data: 112314\n",
      "Creating test data: 107432\n",
      "Creating test data: 52375\n",
      "Creating test data: 118063\n",
      "Creating test data: 72074\n",
      "Creating test data: 134937\n",
      "Creating test data: 105716\n",
      "Creating test data: 51111\n",
      "Creating test data: 11803\n"
     ]
    }
   ],
   "source": [
    "# Create test data by add random noise on randomly selected tracks\n",
    "all_track_ids = tracks.loc[small].index\n",
    "feature_extraction_func = chroma_extraction_func if feature_name == \"chroma\" else mfcc_extraction_func\n",
    "test_track_ids, test_data_feature = create_test_data(all_track_ids, feature_extraction_func, noise_level=0.1, num_data=100)\n",
    "save_pickle(test_data_file_name, test_data_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuyun\\Documents\\cs598_project\\audio2vec\\models.py:18: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, (hn, cn) = self.lstm(inputs, hidden_cell)\n",
      "C:\\Users\\wuyun\\Documents\\cs598_project\\audio2vec\\models.py:18: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, (hn, cn) = self.lstm(inputs, hidden_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 50 audios.\n",
      "Embedded 100 audios.\n",
      "Accuracy is 0.02.\n",
      "Accuracy is 0.02.\n"
     ]
    }
   ],
   "source": [
    "# Create test data embedding vectors\n",
    "test_embedding = embedding(model_file_name, test_data_file_name)\n",
    "\n",
    "test_track_ids, ranking_result_list = evaluate(all_track_ids, all_embedding, test_track_ids, test_embedding, dist_func='cos')\n",
    "test_track_ids, ranking_result_list = evaluate(all_track_ids, all_embedding, test_track_ids, test_embedding, dist_func='norm')\n",
    "save_pickle(\"seq2seq_test_track_ids.pkl\", test_track_ids)\n",
    "save_pickle(\"seq2seq_ranking_result_list.pkl\", ranking_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
