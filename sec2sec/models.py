import torch
import torch.nn as nn
import hyperparameters as hps
import utils
from torch.autograd import Variable

class EncoderRNN(nn.Module):
    def __init__(self, feature_dimension):
        super(EncoderRNN, self).__init__()
        self.lstm = nn.LSTM(feature_dimension, hps.enc_hidden_size, dropout=hps.dropout, bidirectional=True).cuda()
        self.fully_connect = nn.Linear(2 * hps.enc_hidden_size, hps.latent_vector_length).cuda()

    def forward(self, inputs, batch_size, hidden_cell = None):
        if hidden_cell is None:
            h0 = Variable(torch.zeros(2, batch_size, hps.enc_hidden_size).cuda())
            c0 = Variable(torch.zeros(2, batch_size, hps.enc_hidden_size).cuda())
            hidden_cell = (h0, c0)
        output, (hn, cn) = self.lstm(inputs, hidden_cell)
        hidden_forward, hidden_backward = torch.split(hn, 1, 0)
        hidden_final = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)], 1)
        latent_vector = self.fully_connect(hidden_final)
        return latent_vector.squeeze()

class DecoderRNN(nn.Module):
    def __init__(self, feature_dimension):
        super(DecoderRNN, self).__init__()
        self.z_fc = nn.Linear(hps.latent_vector_length, 2 * hps.dec_hidden_size).cuda()
        self.lstm = nn.LSTM(hps.latent_vector_length + feature_dimension, hps.dec_hidden_size, dropout=hps.dropout).cuda()
        self.reconstruct_fc = nn.Linear(hps.dec_hidden_size, feature_dimension).cuda()

    def forward(self, inputs, z, hidden_cell=None):
        if hidden_cell is None:
            h0, c0 = torch.split(torch.tanh(self.z_fc(z)), hps.dec_hidden_size, 1)
            hidden_cell = (h0.unsqueeze(0).contiguous(), c0.unsqueeze(0).contiguous())
        output, (hn, cn) = self.lstm(inputs, hidden_cell)
        frames = self.reconstruct_fc(output)
        return frames


class Seq2seq(nn.Module):
    def __init__(self, feature_dimension):
        super(Seq2seq, self).__init__()
        self.feature_dimension = feature_dimension
        self.encoder = EncoderRNN(self.feature_dimension)
        self.decoder = DecoderRNN(self.feature_dimension)

    def forward(self, inputs):
        z = self.encoder(inputs, hps.batch_size)
        teacher_forcing_inputs = utils.build_teacher_forcing_inputs(inputs, z)

        # Last frame is generated by last frame of teacher forcing inputs. Drop it.
        outputs = self.decoder(teacher_forcing_inputs, z)[:-1]

        return outputs
