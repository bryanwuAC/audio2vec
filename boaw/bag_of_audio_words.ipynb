{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import ast\n",
    "import pickle\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "                tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        tracks['set', 'subset'] = tracks['set', 'subset'].astype(pd.api.types.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "        \n",
    "        \n",
    "\n",
    "#         COLUMNS = [('track', 'license'), ('artist', 'bio'),\n",
    "#                    ('album', 'type'), ('album', 'information')]\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype(pd.api.types.CategoricalDtype())\n",
    "\n",
    "        return tracks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file_name, file_data):\n",
    "    with open(file_name, \"wb\") as fp:\n",
    "        pickle.dump(file_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name):\n",
    "    with open(file_name, \"rb\") as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_from_files(track_id, feature_extraction_func):\n",
    "    extracted_features = []\n",
    "    for num_track,i in enumerate(track_id):\n",
    "        if(num_track % 100 == 0):\n",
    "            print(\"Processed {} tracks\".format(num_track))\n",
    "        filename = get_audio_path(AUDIO_DIR, i)\n",
    "        x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "        x = x[:(10*sr)]\n",
    "        extracted_features.append(feature_extraction_func(x, sr))\n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction_func(x, sr):\n",
    "    stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "    mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_extraction_func(x, sr):\n",
    "    cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12, n_bins=7*12, tuning=None))\n",
    "    f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and features.\n",
    "BAD_TRACK_ID = [98565, 98567, 98569, 99134, 108925, 133297]\n",
    "\n",
    "tracks = load('fma_metadata/tracks.csv')\n",
    "tracks = tracks.drop(labels = BAD_TRACK_ID)\n",
    "\n",
    "genres = load('fma_metadata/genres.csv')\n",
    "features = load('fma_metadata/features.csv')\n",
    "features = features.drop(labels = BAD_TRACK_ID)\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"fma_small\"\n",
    "extracted_features = []\n",
    "small = tracks['set', 'subset'] <= 'small'\n",
    "track_id = tracks.loc[small].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = extract_feature_from_files(track_id, mfcc_extraction_func)\n",
    "# save_pickle('preprocessed_data/mfcc.pkl', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = extract_feature_from_files(track_id, chroma_extraction_func)\n",
    "# save_pickle('preprocessed_data/chroma.pkl', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_track_features_from_id(track_id, selected_track_id, feature_list):\n",
    "    result_feature_list = []\n",
    "    selected_track_index = 0\n",
    "    all_track_index = 0\n",
    "    while all_track_index < track_id.shape[0] and selected_track_index < selected_track_id.shape[0]:\n",
    "        if track_id[all_track_index] == selected_track_id[selected_track_index]:\n",
    "            result_feature_list.append(feature_list[all_track_index])\n",
    "            selected_track_index += 1\n",
    "        all_track_index += 1\n",
    "    return result_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(feature_list):\n",
    "    train_entries = tracks['set', 'split'] == 'training'\n",
    "    test_entries = tracks['set', 'split'] == 'test'\n",
    "\n",
    "    small = tracks['set', 'subset'] <= 'small'\n",
    "    \n",
    "    track_id = tracks.loc[small].index\n",
    "    train_track_id = tracks.loc[small & train_entries].index\n",
    "    test_track_id = tracks.loc[small & test_entries].index\n",
    "    \n",
    "    train_feature_list = select_track_features_from_id(track_id, train_track_id, feature_list)\n",
    "    test_feature_list = select_track_features_from_id(track_id, test_track_id, feature_list)\n",
    "    return train_track_id, test_track_id, train_feature_list, test_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all features and store which feature corresponses to which idx in train_track_id / test_track_id\n",
    "def vectorize_data(feature_list):\n",
    "    feature_idx_list = []\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_idx_list.append(np.ones((feature_list[i].shape[1], 1)) * i)\n",
    "\n",
    "    feature_array = np.hstack(feature_list).T\n",
    "    feature_idx = np.vstack(feature_idx_list)\n",
    "    return feature_array, feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5534576, 1)\n",
      "(5534576, 20)\n"
     ]
    }
   ],
   "source": [
    "# using test_data for training\n",
    "feature_list = load_pickle('preprocessed_data/mfcc.pkl')\n",
    "train_track_id, test_track_id, train_feature_list, test_feature_list = split_data(feature_list)\n",
    "train_feature_array, train_feature_idx = vectorize_data(train_feature_list)\n",
    "train_track_count = len(train_feature_list)\n",
    "                                \n",
    "print (train_feature_idx.shape)\n",
    "print (train_feature_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(feature_array, feature_name):\n",
    "    # zero_mean standard scaler\n",
    "    zero_mean = skl.preprocessing.StandardScaler(with_std=False)\n",
    "    feature_array = zero_mean.fit_transform(feature_array)\n",
    "    pca = skl.decomposition.PCA(n_components=8)\n",
    "    reduced_train_feature_array = pca.fit_transform(feature_array)\n",
    "    save_pickle(\"sklearn_models/{}_pca.pkl\".format(feature_name), pca)\n",
    "    save_pickle(\"sklearn_models/{}_zero_mean.pkl\".format(feature_name), zero_mean)\n",
    "    return reduced_train_feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pca model\n",
    "# mfcc_pca = load_pickle('mfcc_pca.pkl')\n",
    "# reduced_train_feature_array = loaded_pca.transform(train_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_kmeans(feature_array, feature_name, cluster_count):\n",
    "    kmeans = skl.cluster.MiniBatchKMeans(n_clusters=cluster_count, verbose=1, batch_size=3000)\n",
    "    kmeans.fit(feature_array)\n",
    "    kmeans.transform(feature_array)\n",
    "    save_pickle(\"sklearn_models/{}_kmeans.pkl\".format(feature_name), kmeans)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_count = 1000\n",
    "# reduced_train_feature_array = pca(train_feature_array, \"mfcc\")\n",
    "# vector_quantization_result = minibatch_kmeans(reduced_train_feature_array, \"mfcc\", cluster_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(raw_document_vector, document_length):\n",
    "    return raw_document_vector / document_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(documents):\n",
    "    num_documents = documents.shape[1]\n",
    "    num_documents_contain = np.count_nonzero(documents, axis=0)\n",
    "    idf = np.log(np.divide(num_documents, num_documents_contain))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document_vector(raw_document_vector):\n",
    "    document_length = np.sum(raw_document_vector)\n",
    "    normalized_document_vector = np.multiply(tf(raw_document_vector, document_length), idf)\n",
    "    return normalized_document_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_documents(documents):\n",
    "    return np.apply_along_axis(normalize_document_vector, 1, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(query, documents, document_ids, dist_func='cos', num_results=10):\n",
    "    query = normalize_document_vector(query)\n",
    "    distances = np.zeros(documents.shape[0])\n",
    "    for i in range(documents.shape[0]):\n",
    "        if dist_func == 'cos':\n",
    "            distances[i] = distance.cosine(query, documents[i])\n",
    "        elif dist_func == 'norm':\n",
    "            distances[i] = np.linalg.norm(documents[i] - query)\n",
    "    ranking_result_index = np.argsort(distances)\n",
    "    return document_ids[ranking_result_index[:num_results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for chroma method on 100 queries:  1.0\n"
     ]
    }
   ],
   "source": [
    "# def addRandomNoiseToFile(filename, file_id):\n",
    "#     x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "#     x += 0.1 * np.random.rand(len(x))\n",
    "#     librosa.output.write_wav('noised_{}.wav'.format(file_id), x, sr)\n",
    "    \n",
    "def addRandomNoiseToWave(x, noise_level):\n",
    "    x += noise_level * np.random.rand(len(x))\n",
    "    return x\n",
    "\n",
    "def musicToVector(filename, feature_extraction_func, data_processors, noise_level, cluster_size):\n",
    "    zero_mean, pca, kmeans = data_processors\n",
    "    \n",
    "    x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "    x = x[:(10*sr)]\n",
    "    # adding distortion to loaded wave\n",
    "    x = addRandomNoiseToWave(x, noise_level)\n",
    "    extracted_features = feature_extraction_func(x, sr).T\n",
    "    processed_features = zero_mean.transform(extracted_features)\n",
    "    processed_features = pca.transform(processed_features)\n",
    "    kmeans_labels = kmeans.predict(processed_features)\n",
    "    cluster_vector = np.zeros(cluster_size)\n",
    "    for val in kmeans_labels:\n",
    "        cluster_vector[val] += 1\n",
    "    return cluster_vector\n",
    "\n",
    "def loadDataProcessors(name):  \n",
    "    # load zero_mean model\n",
    "    zero_mean = load_pickle('sklearn_models/{}_zero_mean.pkl'.format(name))\n",
    "    # load pca model\n",
    "    pca = load_pickle('sklearn_models/{}_pca.pkl'.format(name))\n",
    "    # load kmeans model\n",
    "    kmeans = load_pickle('sklearn_models/{}_kmeans.pkl'.format(name))\n",
    "    kmeans.verbose = 0\n",
    "\n",
    "    return zero_mean, pca, kmeans\n",
    "\n",
    "def loadTrainTrackClusters(name, cluster_count):\n",
    "    kmeans = load_pickle('sklearn_models/{}_kmeans.pkl'.format(name))\n",
    "    documents = np.zeros((train_track_count, cluster_count))\n",
    "    labels = kmeans.labels_\n",
    "    for i in range(len(labels)):\n",
    "        track_idx = train_feature_idx[i]\n",
    "        documents[int(track_idx)][labels[i]] += 1\n",
    "    return documents\n",
    "\n",
    "def evaluate(feature_name, documents, feature_extract_func, noise_level, dist_func='cos', num_queries=100, cluster_size=1000):\n",
    "    data_processors = loadDataProcessors(feature_name)\n",
    "    chosen_tracks = np.random.choice(train_track_id, num_queries, replace=False)\n",
    "    correct_ranking = 0\n",
    "    ranking_result_list = []\n",
    "    for i, track_id in enumerate(chosen_tracks, 1):\n",
    "        filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "        query = musicToVector(filename, feature_extract_func, data_processors, noise_level, cluster_size)\n",
    "        ranking_result = ranking(query, documents, train_track_id, dist_func)\n",
    "        ranking_result_list.append(ranking_result)\n",
    "        if ranking_result[0] == track_id:\n",
    "            correct_ranking += 1\n",
    "    accuracy = correct_ranking / num_queries\n",
    "    print ('Accuracy for {} method on {} queries: '.format(feature_name, num_queries), accuracy)\n",
    "    return chosen_tracks, ranking_result_list\n",
    "\n",
    "raw_documents = loadTrainTrackClusters(\"chroma\", 1000)\n",
    "idf = compute_idf(raw_documents)\n",
    "normalized_documents = normalize_documents(raw_documents)\n",
    "\n",
    "# mfcc_cos_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0, dist_func='cos', num_queries=100)\n",
    "# mfcc_cos_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0.01, dist_func='cos', num_queries=100)\n",
    "# mfcc_cos_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0.1, dist_func='cos', num_queries=100)\n",
    "\n",
    "# mfcc_norm_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0, dist_func='norm', num_queries=100)\n",
    "# mfcc_norm_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0.01, dist_func='norm', num_queries=100)\n",
    "# mfcc_norm_acc = evaluate('mfcc', normalized_documents, mfcc_extraction_func, noise_level=0.1, dist_func='norm', num_queries=100)\n",
    "\n",
    "test_track_ids, ranking_result_list = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0, dist_func='cos', num_queries=100)\n",
    "# chroma_cos_acc = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0.01, dist_func='cos', num_queries=100)\n",
    "# chroma_cos_acc = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0.1, dist_func='cos', num_queries=100)\n",
    "\n",
    "# chroma_norm_acc = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0, dist_func='norm', num_queries=100)\n",
    "# chroma_norm_acc = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0.01, dist_func='norm', num_queries=100)\n",
    "# chroma_norm_acc = evaluate('chroma', normalized_documents, chroma_extraction_func, noise_level=0.1, dist_func='norm', num_queries=100)\n",
    "\n",
    "save_pickle(\"boaw_test_track_ids.pkl\", test_track_ids)\n",
    "save_pickle(\"boaw_ranking_result_list.pkl\", ranking_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "false_ranking = []\n",
    "for test_index in range(1):\n",
    "    print(\"Testing track id:\", train_track_id[test_index])\n",
    "    original_query = normalized_documents[test_index]\n",
    "    ranking_result = ranking(original_query, normalized_documents, train_track_id, dist_func='cos')\n",
    "    if ranking_result[0] != train_track_id[test_index]:\n",
    "        false_ranking.append((train_track_id[test_index], ranking_result[0]))\n",
    "print(false_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = get_audio_path(AUDIO_DIR, 108037)\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mean = load_pickle('sklearn_models/{}_zero_mean.pkl'.format(\"chroma\"))\n",
    "pca = load_pickle('sklearn_models/{}_pca.pkl'.format(\"chroma\"))\n",
    "kmeans = load_pickle('sklearn_models/{}_kmeans.pkl'.format(\"chroma\"))\n",
    "old_labels = kmeans.labels_\n",
    "kmeans.verbose = 0\n",
    "\n",
    "feature_list = load_pickle('preprocessed_data/chroma.pkl')\n",
    "train_track_id, test_track_id, train_feature_list, test_feature_list = split_data(feature_list)\n",
    "train_feature_array, train_feature_idx = vectorize_data(train_feature_list)\n",
    "train_track_count = len(train_feature_list)\n",
    "\n",
    "processed_features = zero_mean.transform(train_feature_array[:2100])\n",
    "processed_features = pca.transform(processed_features[:2100])\n",
    "new_labels = kmeans.predict(processed_features[:2100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(old_labels[:2100] != new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(filename, feature_extraction_func, data_processors, noise_level, cluster_size):\n",
    "    zero_mean, pca, kmeans = data_processors\n",
    "    \n",
    "    x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "    x = x[:(10*sr)]\n",
    "    # adding distortion to loaded wave\n",
    "#     x = addRandomNoiseToWave(x, noise_level)\n",
    "    extracted_features = feature_extraction_func(x, sr).T\n",
    "    zero_features = zero_mean.transform(extracted_features)\n",
    "    pca_features = pca.transform(zero_features)\n",
    "    kmeans_labels = kmeans.predict(pca_features)\n",
    "#     cluster_vector = np.zeros(cluster_size)\n",
    "#     for val in kmeans_labels:\n",
    "#         cluster_vector[val] += 1\n",
    "    return extracted_features, zero_features, pca_features, kmeans_labels\n",
    "\n",
    "filename = get_audio_path(AUDIO_DIR, 2)\n",
    "data_processors = loadDataProcessors('chroma')\n",
    "extracted_features, zero_features, pca_features, kmeans_labels = test(filename, chroma_extraction_func, data_processors, 0.01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_features = zero_mean.transform(train_feature_array[:2582])\n",
    "processed_features = pca.transform(processed_features[:2582])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03396339 -0.23078826 -0.1691253  ... -0.09072542 -0.09195164\n",
      "  -0.05509767]\n",
      " [-0.03010589 -0.24011316 -0.16976384 ... -0.08827809 -0.0906359\n",
      "  -0.05278084]\n",
      " [-0.02562837 -0.24946558 -0.16951365 ... -0.08589326 -0.08933992\n",
      "  -0.05045947]\n",
      " ...\n",
      " [ 0.22702525 -0.11454669 -0.05175217 ...  0.05255807 -0.09923446\n",
      "  -0.02833947]\n",
      " [ 0.2274325  -0.12803563 -0.04436911 ...  0.05567943 -0.09602342\n",
      "  -0.02975243]\n",
      " [ 0.22830835 -0.14097878 -0.03720105 ...  0.0586235  -0.09259355\n",
      "  -0.03104894]]\n",
      "[[-0.03396339 -0.23078826 -0.1691253  ... -0.09072542 -0.09195164\n",
      "  -0.05509767]\n",
      " [-0.03010589 -0.24011316 -0.16976384 ... -0.08827809 -0.0906359\n",
      "  -0.05278084]\n",
      " [-0.02562837 -0.24946558 -0.16951365 ... -0.08589326 -0.08933992\n",
      "  -0.05045947]\n",
      " ...\n",
      " [ 0.17321961  0.09735506 -0.06236397 ...  0.07582098 -0.10686997\n",
      "  -0.04551584]\n",
      " [ 0.1814824   0.09410527 -0.0617262  ...  0.07613659 -0.10546319\n",
      "  -0.04520431]\n",
      " [ 0.18900968  0.09059635 -0.06124072 ...  0.07672863 -0.10402947\n",
      "  -0.04516938]]\n"
     ]
    }
   ],
   "source": [
    "print(pca_features)\n",
    "print(processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
